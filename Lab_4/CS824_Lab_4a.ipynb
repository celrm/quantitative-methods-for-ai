{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> CS824 - Lab 4a (2022) </div>\n",
    "\n",
    "# Simple application of Bayes Law\n",
    "\n",
    "As usual, follow those parts of the lab that have been set up - sometimes involving aspects of Python that you may not yet be familiar with, but try to make sure you get a feel for what is happening in terms of **probability** and **Bayes**...  There are various 'exercises' which are the elements that should form part of this week's submission (\"SUBMIT\").\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Part 1: Using Bayes to understand medical diagnosis\n",
    "\n",
    "Depending on how familiar you are with the terms from medical diagnosis you may need to refer to the formulae in mini-lecture 4.2 to translate the example below into a function that uses Bayes Law to properly interpret the results from diagnostic tests.\n",
    "\n",
    "## Exercise 1a (SUBMIT)\n",
    "Build a function in Python that takes in the following three parameters:\n",
    "- the prevalence of some disease in a population (sometimes called the 'base rate')\n",
    "- the sensitivity of a diagnostic test (also referred to as the 'true positive rate')\n",
    "- the specificity of a diagnostic test (also referred to as the 'true negative rate')\n",
    "\n",
    "<br> and returns a value that represents the probability that a patient from that population has the disease based on getting a positive result from such a test.\n",
    "\n",
    "Start with the example from the mini-lecture, i.e.:\n",
    "- prevalence of some rare disease = 1 in 5,000\n",
    "- sensitivity = 99%\n",
    "- specificity = 95%\n",
    "\n",
    "<br>Given these parameters your function should return a value of around 0.4%, - i.e. the P(disease | +test).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex1a(prevalence,sensitivity,specificity):\n",
    "    \"\"\"returns a value that represents the probability that a patient from that population has the disease based on getting a positive result from such a test.\n",
    "    P(D|+) = P(+|D)*P(D)/P(+)\n",
    "    P(D) = prevalence\n",
    "    P(+|D) = sensitivity\n",
    "    P(+) = (prevalence*sensitivity + (1-specificity)*(1-prevalence))\n",
    "    \"\"\"\n",
    "    return prevalence*sensitivity/(prevalence*sensitivity + (1-specificity)*(1-prevalence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003945166175181315"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1a(1/5000,0.99,0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercise 1b (SUBMIT)\n",
    "How (if at all) does your belief that this patient has the disease alter if she gets a **second** positive test? (Assume this has the same 'test characteristics' but is run by a different lab, just so that we know the two tests are in some way independent.) Does that makes sense to you?\n",
    "\n",
    "\n",
    "#### The result that I came up with increased the probability to just over 7%. This is now starting to get a bit more serious/worrying...  Did you get the same result? Do you trust this value?  If not, why not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07272066243248045"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1a(ex1a(1/5000,0.99,0.95),0.99,0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I trust it because it has increased in magnitude quite a bit from the last time; and the first test had a very low probability because the disease is very rare and the amount of false positives is big enough to not make the next value as big (i.e. the specificity is not as big as it can be)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1c (SUBMIT)\n",
    "What about if the level of specificity is equal to that of the sensitivity - i.e. both are at 99%.  How does this alter things? (Look at this for both the first and subsequent runs of this 'new improved' test.) \n",
    "\n",
    "#### Did the new outcomes surprise you?  Again would you intuitively accept/'believe' these numbers? How have these exercises impacted on your understanding of how 'sensitivity' and 'specificity' in diagnositc tests should be understood?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019419380149078055"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1a(1/5000,0.99,0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6622297297297294"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1a(ex1a(1/5000,0.99,0.99),0.99,0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it was said in the previous exercise, the specificity marked how probable it was to get a false positive. In this case, the probability is much lower, so it is more probable that our positives are real. In this case, it increases to 2% (still pondering the rarity of the disease) and 66% for the second test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Exercise 1d (SUBMIT)\n",
    "Have a look at the situation for **COVID-19**:\n",
    "- you will need to check the Web for a suitable base rate to explore this issue, as well as commonly accepted test characteristics. If you find suggestions that specificity is 100% (as some do) then you may be more interested in the presence of COVID in an indivdual who has tested NEGATIVE (explain why the positive outome case is 'uninteresting' in this context). You may wish to look at both PCR and lateral flow tests (LFTs) when carrying out this exercise.\n",
    "\n",
    "<br> Which of the parameters seems to have the largest impact on the outcome (i.e. your belief that there really is something that you should be worried about and/or relaxed enough to ignore, given different outcomes)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevalence = 0.02 # https://www.ons.gov.uk/peoplepopulationandcommunity/healthandsocialcare/conditionsanddiseases/articles/coronaviruscovid19latestinsights/infections\n",
    "pcr_sensitivity = 0.87\n",
    "pcr_specificity = 0.99 # https://www.infectiousdiseaseadvisor.com/home/topics/covid19/covid-19-diagnosis-pcr-testing-value/\n",
    "lft_sensitivity = 0.76\n",
    "lft_specificity = 0.99 # https://www.ox.ac.uk/news/2020-11-11-oxford-university-and-phe-confirm-lateral-flow-tests-show-high-specificity-and-are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6397058823529409"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1a(prevalence,pcr_sensitivity,pcr_specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6079999999999998"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1a(prevalence,lft_sensitivity,lft_specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the specificity is 100% then there exists no false positives, so if you are positive, the probability of you having the disease is 100%. This is why it would be more interesting to study the case in which you are negative.\n",
    "\n",
    "It can be seen that the COVID tests have all very high specificity. This means that people that test positive can be certain they are quarantining for a real reason. However, it seems like having a higher sensitivity would be advisable in order to reduce the false negatives and reduce the disease spread.\n",
    "\n",
    "So if you test positive, you are quite sure that you have the disease. However, if you test negative, you might want to take a second test just in case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Part 2: M&Ms and Bayes\n",
    "\n",
    "So-called 'urn' (or 'bag') problems don't always present in the *classic* manner we came across last week - dating back to Bernoulli. The problem below is in the same basic format as the 'urn' problems of last week but allow for a little bit of a twist. This example is based on an example around the American candy, M&Ms and their production over time, and is based on an entry from [Allen Downey's](https://www.allendowney.com/blog/) excellent blog (though as always, any errors introduced in editing are entirely my fault!)\n",
    "\n",
    "> The blue M&M was introduced in 1995.  Before then, the colour mix in a bag of M&Ms was (30% Brown, 20% Yellow, 20% Red, 10% Green, 10% Orange, 10% Tan).  After 1995 it was (24% Blue, 20% Green, 16% Orange, 14% Yellow, 13% Red, 13% Brown).\n",
    "\n",
    "> A friend of mine has two bags of M&Ms, and he tells me that one is from 1994 and one from 1996 but won't tell me which is which. He gives me a yellow M&M, what is the probability that this came from the 1994 bag?\n",
    "\n",
    "Now that you have picked up on the basic ideas of Bayesian reasoning you should see that this seems to be a good candidate, in that we are asked to estimate the probability of a hypothesis (that the yellow M&M is from 1994) given some evidence. It is not immediately obvivous how we might do this but we should be able to take the probabilities that we have been given and work in the 'opposite' direction, i.e. what is the probability that we would have recieved this 'evidence' under the different hypotheses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You may feel that all this reasoning is 'over-kill', but we are going to add a bit more evidence in a moment, so breaking down our thinking in this way will ultimately pay off...\n",
    "\n",
    "Before we see the colour of the M&M, there are two hypotheses, `A` and `B`, both with equal probability:\n",
    "\n",
    "    A: the M&M was from the 94 bag\n",
    "    B: the M&M was from the 96 bag\n",
    "    P(A) = P(B) = 0.5\n",
    "    \n",
    "Then we get some evidence:\n",
    "    \n",
    "    E: the M&M is yellow\n",
    "    \n",
    "We want to know the probability of hypothesis `A`, given the evidence:\n",
    "    \n",
    "    P(A | E)\n",
    "    \n",
    "We *could* enumerate the sample space to estimate this but that will start to become more tricky as we are given more evidence (see below). So instead let's take what we know from Bayes' Theorem, namely that:\n",
    "    \n",
    "    P(A | E) = P(E | A) * P(A) / P(E)\n",
    "    \n",
    "The quantities on the right-hand-side of this equation are all pretty straight-forward to calculate:\n",
    "    \n",
    "    P(E | A) = 0.20\n",
    "    P(E | B) = 0.14\n",
    "    P(A)     = 0.5\n",
    "    P(B)     = 0.5\n",
    "    P(E)     = P(E | A) * P(A) + P(E | B) * P(B) \n",
    "             = 0.20     * 0.5  + 0.14     * 0.5   =   0.17\n",
    "    \n",
    "We can use Bayes Law to get a final answer:\n",
    "   \n",
    "    P(A | E) = P(E | A) * P(A) / P(E) \n",
    "             = 0.20     * 0.5  / 0.17 \n",
    "             = 0.588\n",
    "\n",
    "i.e. There is about a 59% chance that this yellow M&M was taken was the 1994 bag.  \n",
    "\n",
    "You may say, \"well that was a LOT of work to calcuate what was a lot more obvious, by simply noting that 20/34 (i.e. 1994_yellows / all_yellows) is the proportion / likelihood of the yellow coming from the 1994 bag\". And you would be correct, but see whether your mind might change when faced with the next question...  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercise 2a (SUBMIT)\n",
    "\n",
    "Let's think about a slightly more 'interesting' situation...  Say this time that our friend draws one M&M from each bag - the first one is yellow and the seceond one is green. Now how might you go about estimating the probability that the yellow M&M came from the 1994 bag?\n",
    "\n",
    "<br>\n",
    "You should be able to use the approach outlined above to estimate this value. It would be great to build a little 'Bayes estimator' function in Python to explore this and then other selections of M&Ms, so try to create that rather than (or in addition to) working our each option *by hand* (as we did above).\n",
    "\n",
    "<br>\n",
    "(I estimated that there was now a 74% chance that the yellow M&M came from the 1994 bag... Did you find the same?  Does this value make sense to you?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "mybag94 = {\"brown\":0.3,\"yellow\":0.2,\"red\":0.2,\"green\":0.1,\"orange\":0.1,\"tan\":0.1,\"blue\":0}\n",
    "mybag96 = {\"brown\":0.13,\"yellow\":0.14,\"red\":0.13,\"green\":0.2,\"orange\":0.16,\"tan\":0,\"blue\":0.24}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5882352941176471"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BAG1 is 94, given BAG1 extraction is yellow and uniform prior\n",
    "first_extraction = ex1a(0.5, mybag94['yellow'],1-mybag96['yellow'])\n",
    "first_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7407407407407408"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BAG1 is 94, given BAG2 extraction is green and first_extraction prior\n",
    "second_extraction = ex1a(first_extraction,mybag96['green'],1-mybag94['green'])\n",
    "second_extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value makes sense. It is more probable that BAG1 is the 94 because there are more yellows than in 96, and there are more greens in the 96 than in the 94. So both higher probabilities add up to a high number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Do we really need Bayes Law?\n",
    "\n",
    "An alternative approach was suggested by Peter Norvig as he reflected on Allen Downey's example...\n",
    "\n",
    "In a sense it is curious that this problem comes from a section titled by Downey as **My favorite Bayes's Theorem Problems**, as you might expect that you would need to invoke Bayes Theorem to solve it. However, the enumerative approach outlined below shows that is not strictly necessary.\n",
    "\n",
    "Yes, Bayes Theorem allows you to do less calculation but at the cost of more algebra; that is a great trade-off if you are working with pencil and paper. Enumerating the state space allows you to do less algebra at the cost of more calculation; sometimes a good trade-off if you have a computer. Using both approaches may help you to more fully understand Bayes theorem and how it works (or at least confirm that the algebra agrees with the enumerated outcome!).\n",
    "\n",
    "We can use some of the code that was introduced to us in Norvig's tutorial examples of urn problems from last week. We will start by re-introducing the various functions that he developed there, though here they are replaced with slightly 'enhanced' versions (but essentially acheive the same results).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from fractions import Fraction\n",
    "\n",
    "is_predicate = callable\n",
    "\n",
    "def P(event, space): \n",
    "    \"\"\"The probability of an event, given a sample space of equiprobable outcomes. \n",
    "    event: a collection of outcomes, or a predicate that is true of outcomes in the event. \n",
    "    space: a set of outcomes or a probability distribution of {outcome: frequency} pairs.\"\"\"\n",
    "    if is_predicate(event):\n",
    "        event = such_that(event, space)\n",
    "    if isinstance(space, ProbDist):\n",
    "        return sum(space[o] for o in space if o in event)\n",
    "    else:\n",
    "        return Fraction(len(event & space), len(space))\n",
    "    \n",
    "def such_that(predicate, space): \n",
    "    \"\"\"The outcomes in the sample pace for which the predicate is true.\n",
    "    If space is a set, return a subset {outcome,...};\n",
    "    if space is a ProbDist, return a ProbDist {outcome: frequency,...};\n",
    "    in both cases only with outcomes where predicate(element) is true.\"\"\"\n",
    "    if isinstance(space, ProbDist):\n",
    "        return ProbDist({o:space[o] for o in space if predicate(o)})\n",
    "    else:\n",
    "        return {o for o in space if predicate(o)}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "To tackle this particulars of this problem, we'll need to represent the probability distributions of the difference M&Ms in each bag.  We define a `ProbDist` function and then use it to create the distribution of differing colours of M&Ms contained in `bag94` and `bag96`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "class ProbDist(dict):\n",
    "    \"A Probability Distribution; an {outcome: probability} mapping.\"\n",
    "    def __init__(self, mapping=(), **kwargs):\n",
    "        self.update(mapping, **kwargs)\n",
    "        # Make probabilities sum to 1.0; assert no negative probabilities\n",
    "        total = sum(self.values())\n",
    "        for outcome in self:\n",
    "            self[outcome] = self[outcome] / total\n",
    "            assert self[outcome] >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "bag94 = ProbDist(brown=30, yellow=20, red=20, green=10, orange=10, tan=10)\n",
    "bag96 = ProbDist(blue=24, green=20, orange=16, yellow=14, red=13, brown=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brown': 0.3,\n",
       " 'yellow': 0.2,\n",
       " 'red': 0.2,\n",
       " 'green': 0.1,\n",
       " 'orange': 0.1,\n",
       " 'tan': 0.1}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can check the contents of a bag (or more correctly the propotions of differing colour contents in a bag)\n",
    "bag94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "We can now define `two_MM` as the joint distribution - the sample space for picking two M&Ms, one from each of the bags defined by these two distributions. The outcome `'brown - blue'` means that a brown M&M was selected from the 1994 bag and that a blue one came from the 1996 bag. There will be no entry for `blue - brown` as there were no blue M&Ms in the bags from before 1995, but for many selections we are able to find the values for various `a - b` and `b - a` outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brown - blue': 0.07199999999999997,\n",
       " 'brown - green': 0.05999999999999997,\n",
       " 'brown - orange': 0.04799999999999998,\n",
       " 'brown - yellow': 0.04199999999999998,\n",
       " 'brown - red': 0.038999999999999986,\n",
       " 'brown - brown': 0.038999999999999986,\n",
       " 'yellow - blue': 0.04799999999999998,\n",
       " 'yellow - green': 0.03999999999999999,\n",
       " 'yellow - orange': 0.03199999999999999,\n",
       " 'yellow - yellow': 0.02799999999999999,\n",
       " 'yellow - red': 0.025999999999999992,\n",
       " 'yellow - brown': 0.025999999999999992,\n",
       " 'red - blue': 0.04799999999999998,\n",
       " 'red - green': 0.03999999999999999,\n",
       " 'red - orange': 0.03199999999999999,\n",
       " 'red - yellow': 0.02799999999999999,\n",
       " 'red - red': 0.025999999999999992,\n",
       " 'red - brown': 0.025999999999999992,\n",
       " 'green - blue': 0.02399999999999999,\n",
       " 'green - green': 0.019999999999999993,\n",
       " 'green - orange': 0.015999999999999993,\n",
       " 'green - yellow': 0.013999999999999995,\n",
       " 'green - red': 0.012999999999999996,\n",
       " 'green - brown': 0.012999999999999996,\n",
       " 'orange - blue': 0.02399999999999999,\n",
       " 'orange - green': 0.019999999999999993,\n",
       " 'orange - orange': 0.015999999999999993,\n",
       " 'orange - yellow': 0.013999999999999995,\n",
       " 'orange - red': 0.012999999999999996,\n",
       " 'orange - brown': 0.012999999999999996,\n",
       " 'tan - blue': 0.02399999999999999,\n",
       " 'tan - green': 0.019999999999999993,\n",
       " 'tan - orange': 0.015999999999999993,\n",
       " 'tan - yellow': 0.013999999999999995,\n",
       " 'tan - red': 0.012999999999999996,\n",
       " 'tan - brown': 0.012999999999999996}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def joint(A, B, sep=''):\n",
    "    \"\"\"The joint distribution of two independent probability distributions. \n",
    "    Result is all entries of the form {a+sep+b: P(a)*P(b)}\"\"\"\n",
    "    return ProbDist({a + sep + b: A[a] * B[b]\n",
    "                    for a in A\n",
    "                    for b in B})\n",
    "\n",
    "two_MM = joint(bag94, bag96, ' - ')\n",
    "two_MM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "So now we can look at the possible ways in which we could end up with a \"one is yellow and one is green\" outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'yellow - green': 0.7407407407407408, 'green - yellow': 0.25925925925925924}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def yellow_and_green(outcome): return 'yellow' in outcome and 'green' in outcome\n",
    "\n",
    "such_that(yellow_and_green, two_MM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "As you can see, these two numbers must sum to 1... if we have a 'yellow and green' outcome, then either we picked them in the order of the 94/96, or order of the 96/94, bags.\n",
    "\n",
    "We therefore don't really need this last/next cell, but if we wanted to test in Python...\n",
    "\n",
    "We can answer the question: given that we got a yellow and a green (but don't know which comes from which bag), what is the probability that the yellow came from the 1994 bag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7407407407407408"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def yellow94(outcome): return outcome.startswith('yellow')\n",
    "\n",
    "P(yellow94, such_that(yellow_and_green, two_MM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we end up with the same outcome as when we used Bayes' Rule in the previous section. Take some time (in the little exercise below) to reflect on these two approaches with some additional examples and provide some comments on your thoughts regarding the approach/outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercise 2b (SUBMIT)\n",
    "\n",
    "Try some alternative outcomes - say that you were given an **orange and a red M&M**.  What is the probability that the orange M&M came from the 1994 bag?  \n",
    "\n",
    "What about if you got a **tan and a red**?  What is the probabilty that the red came from the 1994 bag?\n",
    "\n",
    "You should try both the 'Bayesian' and the enumerative (Norvig's) approach.  Which did you find easier?  Which seemed more intuitive to you and why?\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2888888888888889"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def orange_and_red(outcome): return 'orange' in outcome and 'red' in outcome\n",
    "def orange94(outcome): return outcome.startswith('orange')\n",
    "\n",
    "P(orange94, such_that(orange_and_red, two_MM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2888888888888889"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BAG1 is 94, given BAG1 extraction is orange and uniform prior\n",
    "ex2b_1 = ex1a(0.5, mybag94['orange'],1-mybag96['orange'])\n",
    "# BAG1 is 94, given BAG2 extraction is red and extraction 1\n",
    "ex2b_2 = ex1a(ex2b_1, mybag96['red'],1-mybag94['red'])\n",
    "ex2b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tan_and_red(outcome): return 'tan' in outcome and 'red' in outcome\n",
    "def red94(outcome): return outcome.startswith('red')\n",
    "\n",
    "P(red94, such_that(tan_and_red, two_MM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BAG1 is 94, given BAG2 extraction is tan and uniform prior ->>> this is 0!!! this is why it cannot happen\n",
    "ex2b2_1 = ex1a(0.5, mybag96['tan'],1-mybag94['tan'])\n",
    "print(ex2b2_1)\n",
    "# BAG1 is 94, given BAG1 extraction is red and extraction 1\n",
    "ex2b2_2 = ex1a(ex2b2_1, mybag94['red'],1-mybag96['red'])\n",
    "ex2b2_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I personally find the Bayesian approach more intuitive because of the updating of beliefs system, which is methodical. The counting approach feels more like a black box. However it is also easier to code and to generalise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
